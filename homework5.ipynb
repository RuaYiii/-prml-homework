{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dara_set_1 = datasets.load_iris()  \n",
    "X_set1=dara_set_1.data\n",
    "y_set1=dara_set_1.target\n",
    "\n",
    "dara_set_2=datasets.load_breast_cancer()\n",
    "X_set2=dara_set_2.data\n",
    "y_set2=dara_set_2.target\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_set1,y_set1,test_size=0.33,random_state=0)\n",
    "x_train_2,x_test_2,y_train_2,y_test_2 = train_test_split(X_set2,y_set2,test_size=0.33,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class MaxEnt(object):\n",
    "\n",
    "    def init_params(self, X, Y,num_train=500):\n",
    "        self.X_ = X \n",
    "        self.Y_ = set()\n",
    "        self.num_train=num_train #训练轮数\n",
    "        self.cal_Vxy(X, Y)  # 计算v(X=x,Y=y)\n",
    "\n",
    "        self.N = len(X) # 训练集大小\n",
    "        self.n = len(self.Vxy)  # 数据集中(x,y)对数\n",
    "        self.lr= 0.0001 # 学习率\n",
    "        self.build_dict() # 构建字典\n",
    "        self.cal_Pxy() # 计算P(X=x,Y=y)\n",
    "\n",
    "    def cal_Vxy(self, X, Y): # 计算v(X=x,Y=y)\n",
    "        self.Vxy = defaultdict(int)  #字典映射\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            x_, y = X[i], Y[i]\n",
    "            self.Y_.add(y) \n",
    "            for x in x_:\n",
    "                self.Vxy[(x, y)] += 1 \n",
    "\n",
    "    def build_dict(self): # 构建字典--用于存储(x,y)对\n",
    "        self.id2xy = {}\n",
    "        self.xy2id = {}\n",
    "        for i, (x, y) in enumerate(self.Vxy):\n",
    "            self.id2xy[i] = (x, y)\n",
    "            self.xy2id[(x, y)] = i\n",
    "\n",
    "    def cal_Pxy(self): # 计算P(X=x,Y=y)\n",
    "        self.Pxy = defaultdict(float)\n",
    "        for id in range(self.n):\n",
    "            (x, y) = self.id2xy[id]\n",
    "            self.Pxy[id] = float(self.Vxy[(x, y)]) / float(self.N) #计算P(X=x,Y=y)\n",
    "\n",
    "\n",
    "    def cal_Zx(self, X, y):\n",
    "        '''\n",
    "        计算Zw(x/yi)，根据P85公式6.23，Zw(x)未相加前的单项\n",
    "        '''\n",
    "        result = 0.0\n",
    "        for x in X:\n",
    "            if (x,y) in self.xy2id:\n",
    "                id = self.xy2id[(x, y)]\n",
    "                result += self.w[id]\n",
    "        return (math.exp(result), y)\n",
    "\n",
    "    def cal_Pyx(self, X):\n",
    "        '''\n",
    "        计算P(y|x),根据P85公式6.22\n",
    "        '''\n",
    "        Pyxs = [(self.cal_Zx(X, y)) for y in self.Y_]\n",
    "        Zwx = sum([prob for prob, y in Pyxs])\n",
    "        return [(prob / Zwx, y) for prob, y in Pyxs]\n",
    "\n",
    "    def cal_Epfi(self):\n",
    "        '''\n",
    "        计算Ep(fi),根据P83最上面的公式\n",
    "        '''\n",
    "        self.Epfi = [0.0 for i in range(self.n)]\n",
    "\n",
    "        for i, X in enumerate(self.X_):\n",
    "            Pyxs = self.cal_Pyx(X)\n",
    "\n",
    "            for x in X:\n",
    "                for Pyx, y in Pyxs:\n",
    "                    if (x,y) in self.xy2id:\n",
    "                        id = self.xy2id[(x, y)]\n",
    "\n",
    "                        self.Epfi[id] += Pyx * (1.0 / self.N)\n",
    "\n",
    "\n",
    "    def train(self, X, Y,test_x,test_y):\n",
    "\n",
    "        self.init_params(X, Y) # 初始化参数\n",
    "        self.w = [0.0 for i in range(self.n)] # 初始化w--0\n",
    "        max_iteration = self.num_train  # 最大迭代次数\n",
    "        for times in range(max_iteration):\n",
    "            if times%100==0: #每100轮输出一次\n",
    "                _p=self.predict(test_x)\n",
    "                acc=accuracy_score(test_y,_p)\n",
    "                print(f\"目前训练轮数是 : {times} | 正确率是 :{acc}\")\n",
    "            # 第二步：求δi\n",
    "            detas = []\n",
    "            self.cal_Epfi()\n",
    "            for i in range(self.n):\n",
    "                deta = self.lr * math.log(self.Pxy[i] / self.Epfi[i])  # 指定的特征函数为指示函数，因此E~p(fi)等于Pxy\n",
    "                detas.append(deta)\n",
    "            self.w = [self.w[i] + detas[i] for i in range(self.n)] # 更新w\n",
    "\n",
    "    def predict(self, testset):\n",
    "        results = []\n",
    "        for test in testset:\n",
    "            result = self.cal_Pyx(test)\n",
    "            results.append(max(result, key=lambda x: x[0])[1])\n",
    "        return results\n",
    "\n",
    "\n",
    "def rebuild_features(features):\n",
    "    '''\n",
    "    最大熵模型中的f(x,y)中的x是单独的一个特征,不是一个n维特征向量，因此我们需要对每个维度特征加一个区分标签 \n",
    "    具体地：将原feature的（a0,a1,a2,a3,a4,...） 变成 (0_a0,1_a1,2_a2,3_a3,4_a4,...)形式\n",
    "    '''\n",
    "    new_features = []\n",
    "    for feature in features:\n",
    "        new_feature = []\n",
    "        for i, f in enumerate(feature):\n",
    "            new_feature.append(str(i) + '_' + str(f))\n",
    "        new_features.append(new_feature)\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #(100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = rebuild_features(x_train)\n",
    "train_features_2 = rebuild_features(x_train_2)\n",
    "\n",
    "test_features = rebuild_features(x_test)\n",
    "test_features_2 = rebuild_features(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前训练轮数是 : 0 | 正确率是 :0.32\n",
      "目前训练轮数是 : 100 | 正确率是 :0.92\n",
      "目前训练轮数是 : 200 | 正确率是 :0.92\n",
      "目前训练轮数是 : 300 | 正确率是 :0.92\n",
      "目前训练轮数是 : 400 | 正确率是 :0.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met = MaxEnt()\n",
    "met.train(train_features, y_train,test_features,y_test)\n",
    "test_predict = met.predict(test_features)\n",
    "score = accuracy_score(y_test, test_predict)\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前训练轮数是 : 0 | 正确率是 :0.35638297872340424\n",
      "目前训练轮数是 : 100 | 正确率是 :0.7127659574468085\n",
      "目前训练轮数是 : 200 | 正确率是 :0.7127659574468085\n",
      "目前训练轮数是 : 300 | 正确率是 :0.7127659574468085\n",
      "目前训练轮数是 : 400 | 正确率是 :0.7127659574468085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7127659574468085"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met = MaxEnt()\n",
    "met.train(train_features_2, y_train_2,test_features_2,y_test_2)\n",
    "test_predict = met.predict(test_features_2)\n",
    "score = accuracy_score(y_test_2, test_predict)\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKAQAAAABTUiuoAAAB40lEQVR4nO2aQY7qMAyGP79WmmWQ5gAcJb3ZO9PcoD0KN2iWSEH/LJKWAqMRjARkYS8sar6FJetv7Lgm7rTp370kOOqoo4466ugzUavWw7QDSD02pCU8PD0BRx9BoyRpBvt/qCXTSCdJ0iX6nAQcfQRNVUIaAaIyNgBFb69IwNE/o9PuZKVub0rA0R+tv3o2wtGIhw9Z/HpFAo7+oVpBQAIBYtpntDw+NwFHH0DZ9hF0Is5nt4SjJI1vz9XRUq2NjQCE67BXqx3UhjJg9VAFVv+2gZO9IAFH77PNm7AOXeuUFXJp6F1braDLm3AGoNPGxbkrxfNzqxV0rVYnCPqhwciurWbQ5U0YVBR1llqt4BrzarWCakx90REkM6Z9BkIGwtFvdZtBy3RsUSDSZzZC7i3OqLSC8euj/np/ro4uh1JY3KYdLE7eZTSD1nMrzkCc1zv4cmTVmFerFfT6LqNGF0V5T9gget4dl+l4BCD1i3t6Ao4+gsZ1RJ72RyuNISHDtOt8d9wMenluXYzIxbzLaAi93kaK1GeRTgZhxki2LLnenquj16gNIRcnHcyIcycbXpiAo7/Yze54sroxNkLuBdm11Qx6sztebwzZrJL93GoDLdo6f36hG+factRRRx11tB30G++NhDt7mViiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<qrcode.image.pil.PilImage at 0x2820f4aac70>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#无关的东西\n",
    "import qrcode\n",
    "from qrcode.util import *\n",
    "\n",
    "def hack_put(self, num, length):\n",
    "    if num == 0:\n",
    "        num = 233 # make a fake length\n",
    "    for i in range(length):\n",
    "        self.put_bit(((num >> (length - i - 1)) & 1) == 1)\n",
    "\n",
    "qrcode.util.BitBuffer.put = hack_put\n",
    "\n",
    "qr = qrcode.QRCode(2, qrcode.constants.ERROR_CORRECT_M, mask_pattern=0)\n",
    "\n",
    "num_data = QRData('1145141', MODE_NUMBER)\n",
    "data = QRData(b'.', MODE_8BIT_BYTE)\n",
    "hack_data = QRData(b'', MODE_8BIT_BYTE)\n",
    "\n",
    "# make sure all data is fit to the max content length for this version\n",
    "qr.add_data(num_data)\n",
    "qr.add_data(data)\n",
    "qr.add_data(num_data)\n",
    "qr.add_data(data)\n",
    "qr.add_data(num_data)\n",
    "qr.add_data(data)\n",
    "qr.add_data(num_data)\n",
    "# add a zero length data to make the length of the data to be 233\n",
    "qr.add_data(hack_data)\n",
    "\n",
    "qr.make_image()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
